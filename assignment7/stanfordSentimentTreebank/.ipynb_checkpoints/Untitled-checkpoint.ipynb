{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after joined \n",
      " ___________\n",
      "                                                    phrase  sentiment  \\\n",
      "id                                                                     \n",
      "22935                                                 ! '    0.52778   \n",
      "18235                                                ! ''    0.50000   \n",
      "179257                                             ! Alas    0.44444   \n",
      "22936                                         ! Brilliant    0.86111   \n",
      "40532                                       ! Brilliant !    0.93056   \n",
      "...                                                   ...        ...   \n",
      "220441  zoning ordinances to protect your community fr...    0.13889   \n",
      "179256                                          zzzzzzzzz    0.19444   \n",
      "220442                                               élan    0.51389   \n",
      "220443                                                  É    0.50000   \n",
      "220444                   É um passatempo descompromissado    0.50000   \n",
      "\n",
      "                 fine    coarse  splitset_label  \n",
      "id                                               \n",
      "22935         neutral   neutral             NaN  \n",
      "18235         neutral   neutral             NaN  \n",
      "179257        neutral   neutral             NaN  \n",
      "22936   very positive  positive             NaN  \n",
      "40532   very positive  positive             NaN  \n",
      "...               ...       ...             ...  \n",
      "220441  very negative  negative             NaN  \n",
      "179256  very negative  negative             NaN  \n",
      "220442        neutral   neutral             NaN  \n",
      "220443        neutral   neutral             NaN  \n",
      "220444        neutral   neutral             NaN  \n",
      "\n",
      "[239245 rows x 5 columns]\n",
      "partition \n",
      " ___________\n",
      "                                                    phrase  sentiment  \\\n",
      "id                                                                     \n",
      "22935                                                 ! '    0.52778   \n",
      "18235                                                ! ''    0.50000   \n",
      "179257                                             ! Alas    0.44444   \n",
      "22936                                         ! Brilliant    0.86111   \n",
      "40532                                       ! Brilliant !    0.93056   \n",
      "...                                                   ...        ...   \n",
      "220441  zoning ordinances to protect your community fr...    0.13889   \n",
      "179256                                          zzzzzzzzz    0.19444   \n",
      "220442                                               élan    0.51389   \n",
      "220443                                                  É    0.50000   \n",
      "220444                   É um passatempo descompromissado    0.50000   \n",
      "\n",
      "                 fine    coarse  splitset_label  \n",
      "id                                               \n",
      "22935         neutral   neutral               1  \n",
      "18235         neutral   neutral               1  \n",
      "179257        neutral   neutral               1  \n",
      "22936   very positive  positive               1  \n",
      "40532   very positive  positive               1  \n",
      "...               ...       ...             ...  \n",
      "220441  very negative  negative               1  \n",
      "179256  very negative  negative               1  \n",
      "220442        neutral   neutral               1  \n",
      "220443        neutral   neutral               1  \n",
      "220444        neutral   neutral               1  \n",
      "\n",
      "[236076 rows x 5 columns]\n",
      "\n",
      " --------\n",
      "partition \n",
      " ___________\n",
      "                                                    phrase  sentiment  \\\n",
      "id                                                                     \n",
      "13691               -LRB- A -RRB- rare , beautiful film .   0.958330   \n",
      "13695   -LRB- Drumline -RRB- is entertaining for what ...   0.736110   \n",
      "13696   -LRB- Schweiger is -RRB- talented and terribly...   0.777780   \n",
      "13697   -LRB- Wendigo is -RRB- why we go to the cinema...   0.652780   \n",
      "24114   ... Blade II is more enjoyable than the origin...   0.916670   \n",
      "...                                                   ...        ...   \n",
      "38545   the plot is so amusingly contrived and outland...   0.472220   \n",
      "174825  the story itself is uninteresting , and the so...   0.083333   \n",
      "39780   very solid , very watchable first feature for ...   0.777780   \n",
      "238547                              well worth the time .   0.819440   \n",
      "178923  would seem to have a lock on the title of ugli...   0.097222   \n",
      "\n",
      "                 fine    coarse  splitset_label  \n",
      "id                                               \n",
      "13691   very positive  positive               2  \n",
      "13695        positive  positive               2  \n",
      "13696        positive  positive               2  \n",
      "13697        positive  positive               2  \n",
      "24114   very positive  positive               2  \n",
      "...               ...       ...             ...  \n",
      "38545         neutral   neutral               2  \n",
      "174825  very negative  negative               2  \n",
      "39780        positive  positive               2  \n",
      "238547  very positive  positive               2  \n",
      "178923  very negative  negative               2  \n",
      "\n",
      "[2125 rows x 5 columns]\n",
      "\n",
      " --------\n",
      "partition \n",
      " ___________\n",
      "                                                    phrase  sentiment  \\\n",
      "id                                                                     \n",
      "221765  ... Brian De Palma is utterly mad : cinema mad...    0.58333   \n",
      "221766  ... Designed to provide a mix of smiles and te...    0.22222   \n",
      "24121   ... Mafia , rap stars and hood rats butt their...    0.65278   \n",
      "142768  ... a boring parade of talking heads and techn...    0.27778   \n",
      "43848   ... a fun little timewaster , helped especiall...    0.65278   \n",
      "...                                                   ...        ...   \n",
      "34425   may not have generated many sparks , but with ...    0.59722   \n",
      "235688  should be seen at the very least for its spasm...    0.54167   \n",
      "38233   the film tunes into a grief that could lead a ...    0.65278   \n",
      "39967   what really makes it special is that it pulls ...    1.00000   \n",
      "238627  when Leguizamo finally plugged an irritating c...    0.25000   \n",
      "\n",
      "                 fine    coarse  splitset_label  \n",
      "id                                               \n",
      "221765        neutral   neutral               3  \n",
      "221766       negative  negative               3  \n",
      "24121        positive  positive               3  \n",
      "142768       negative  negative               3  \n",
      "43848        positive  positive               3  \n",
      "...               ...       ...             ...  \n",
      "34425         neutral   neutral               3  \n",
      "235688        neutral   neutral               3  \n",
      "38233        positive  positive               3  \n",
      "39967   very positive  positive               3  \n",
      "238627       negative  negative               3  \n",
      "\n",
      "[1044 rows x 5 columns]\n",
      "\n",
      " --------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas\n",
    "\n",
    "\n",
    "def get_phrase_sentiments(base_directory):\n",
    "    def group_labels(label):\n",
    "        if label in [\"very negative\", \"negative\"]:\n",
    "            return \"negative\"\n",
    "        elif label in [\"positive\", \"very positive\"]:\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"neutral\"\n",
    "\n",
    "    dictionary = pandas.read_csv(os.path.join(base_directory, \"dictionary.txt\"), sep=\"|\")\n",
    "    dictionary.columns = [\"phrase\", \"id\"]\n",
    "    dictionary = dictionary.set_index(\"id\")\n",
    "    \n",
    "    sentiment_labels = pandas.read_csv(os.path.join(base_directory, \"sentiment_labels.txt\"), sep=\"|\")\n",
    "    sentiment_labels.columns = [\"id\", \"sentiment\"]\n",
    "    sentiment_labels = sentiment_labels.set_index(\"id\")\n",
    "    phrase_sentiments = dictionary.join(sentiment_labels)\n",
    "    \n",
    "    phrase_sentiments[\"fine\"] = pandas.cut(phrase_sentiments.sentiment, [0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                           include_lowest=True,\n",
    "                                           labels=[\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"])\n",
    "    phrase_sentiments[\"coarse\"] = phrase_sentiments.fine.apply(group_labels)\n",
    "    return phrase_sentiments\n",
    "\n",
    "\n",
    "def get_sentence_partitions(base_directory):\n",
    "    sentences = pandas.read_csv(os.path.join(base_directory, \"datasetSentences.txt\"), index_col=\"sentence_index\",\n",
    "                                sep=\"\\t\") \n",
    "    splits = pandas.read_csv(os.path.join(base_directory, \"datasetSplit.txt\"), index_col=\"sentence_index\")\n",
    "    return sentences.join(splits).set_index(\"sentence\")\n",
    "\n",
    "\n",
    "def partition(base_directory):\n",
    "    phrase_sentiments = get_phrase_sentiments(base_directory)\n",
    "#     print('phrase_sentiments \\n ___________\\n',phrase_sentiments)\n",
    "#     print('\\n --------')\n",
    "    sentence_partitions = get_sentence_partitions(base_directory)\n",
    "#     print('sentence_partitions \\n ___________\\n',sentence_partitions)\n",
    "#     print('\\n --------')\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    data = phrase_sentiments.join(sentence_partitions, on=\"phrase\")\n",
    "    print('after joined \\n ___________\\n', data)\n",
    "    # set all the ones without split labels into train set(this particularly includes phrases)\n",
    "    data[\"splitset_label\"] = data[\"splitset_label\"].fillna(1).astype(int)\n",
    "    print('are there nulls????????????????????',pd.isna(data[\"sentiment\"]))\n",
    "    data[\"phrase\"] = data[\"phrase\"].str.replace(r\"\\s('s|'d|'re|'ll|'m|'ve|n't)\\b\", lambda m: m.group(1))\n",
    "    return data.groupby(\"splitset_label\")\n",
    "\n",
    "\n",
    "base_directory, output_directory = './','./'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "for splitset, partition in partition(base_directory):\n",
    "    print('partition \\n ___________\\n',partition)\n",
    "    print('\\n --------')\n",
    "    split_name = {1: \"train\", 2: \"test\", 3: \"dev\"}[splitset]\n",
    "    filename = os.path.join(output_directory, \"stanford-sentiment-treebank.%s.csv\" % split_name)\n",
    "    # delete the split label column and save to a separate file\n",
    "    del partition[\"splitset_label\"]\n",
    "    partition.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11851</th>\n",
       "      <td>A real snooze .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11852</th>\n",
       "      <td>No surprises .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11853</th>\n",
       "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11854</th>\n",
       "      <td>Her fans walked out muttering words like `` ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11855</th>\n",
       "      <td>In this case zero .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11855 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         sentence\n",
       "sentence_index                                                   \n",
       "1               The Rock is destined to be the 21st Century 's...\n",
       "2               The gorgeously elaborate continuation of `` Th...\n",
       "3                                  Effective but too-tepid biopic\n",
       "4               If you sometimes like to go to the movies to h...\n",
       "5               Emerges as something rare , an issue movie tha...\n",
       "...                                                           ...\n",
       "11851                                             A real snooze .\n",
       "11852                                              No surprises .\n",
       "11853           We 've seen the hippie-turned-yuppie plot befo...\n",
       "11854           Her fans walked out muttering words like `` ho...\n",
       "11855                                         In this case zero .\n",
       "\n",
       "[11855 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pandas.read_csv(os.path.join(base_directory, \"datasetSentences.txt\"), index_col=\"sentence_index\",\n",
    "                                sep=\"\\t\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
